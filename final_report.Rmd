---
title: "Final Report"
author: "Jonathan Neimann"
date: "2024-12-08"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
spotify30k = read.csv("spotify_songs.csv")
spotify30k <- spotify30k[grepl("[a-zA-Z]", spotify30k$track_artist), ]
```

# Abstract

This study explores the relationship between various song attributes and their popularity on Spotify, leveraging a dataset of nearly 30,000 songs obtained from the Spotify API. Spotify calculates popularity using an algorithm primarily based on the total number of plays a track has had, the recency of those plays and is scaled form 0-100. The analysis focuses on understanding how specific audio features and contextual metadata—such as genre, acousticness, danceability, valence, duration, key, and mode—correlate with this track popularity. Through a combination of descriptive and inferential statistical methods, alongside data visualizations, key patterns in the data are highlighted. Predictive modeling techniques are employed to attempt to identify the most influential factors driving popularity, hopefully offering insights for artists, producers, and marketers aiming to enhance the appeal of their tracks in the competitive music streaming landscape.

# Introduction

The rapid evolution of music streaming platforms has revolutionized the way audiences consume music, with Spotify emerging as the leading player in this space. Spotify provides not only an extensive catalog of songs but also rich metadata and audio analysis for each track, offering a unique opportunity to study the factors that drive a song's popularity. Among these is track popularity, an algorithmically calculated metric primarily influenced by the total number of plays a track has received and the recency of those plays. This metric is measured on a 0-100 scale and provides valuable insights into user preferences and the dynamics of modern music consumption.

This project comes from a place of personal interest, inspired by my academic background and passion for music. Having completed an undergraduate degree in music, I have long been fascinated by the interplay between musical composition and audience reception. My love for music and curiosity about how modern algorithms shape music discovery motivated me to undertake this project. The connection between audio attributes and commercial success represents a compelling intersection of art and data science, which I sought to explore through this work.

Using the "30000 Spotify Songs" dataset from Kaggle, which includes nearly 30,000 tracks, this research focuses on understanding the relationship between key audio attributes and contextual factors that affect a track's popularity on Spotify. Attributes such as acousticness, danceability, valence, duration, key, and mode—derived from Spotify's audio analysis—describe intrinsic musical qualities. These features, combined with metadata such as genre provide a comprehensive framework to analyze patterns in popular music.

Despite the rich dataset, challenges emerged during the analysis, particularly with incomplete or non-standardized metadata. The track_artist field, in particular, made it difficult to fully interpret the popularity metric. Addressing this issue required key emphasis on this variable.

This research employs descriptive analytics, data visualization, and predictive modeling to identify trends and influential factors. The findings aim to shed light on how various song attributes offer insights for artists, producers, and marketers in crafting music that resonates with audiences. By exploring the interplay of musical characteristics and popularity, this project combines statistics and my passion for music to contribute to a deeper understanding of what makes a song successful in the competitive streaming landscape.

# Method

## Visualizations

The first step of this process was to analyze the track_popularity metric from the dataset using various graphs to visualize the data and what we are dealing with. There were many different graphs I explored starting with the most basic of just graphing the density of the target variable. 

```{r, echo=FALSE}
#popularity distribution
hist(spotify30k$track_popularity, 
     main = "Distribution of Track Popularity", 
     xlab = "Track Popularity", 
     col = "blue")
```

We can see right away that there is a significant spike at the very lower ends of popularity and then a slightly left skewed distribution after that. I conducted some tests to determine the main driving force of this spike was track_artist and that within this sample of songs, some artists just did not have the same pull power of other artists in the dataset. Because of this I decided to eliminate all observations that had a track_populartity of below 5. Although this is eliminating some data (around 4000 observations) and created bias, I felt it was necessary to perform proper analysis as it reduces noise significantly and focuses on  on tracks with some level of audience engagement.

Here is the resulting distribution for this dataset. 

```{r, echo=FALSE}
# Create a new dataframe where track_popularity is 5 or higher
spotify_popularity <- spotify30k[spotify30k$track_popularity >= 5, ]

hist(spotify_popularity$track_popularity, 
     main = "Distribution of Track Popularity", 
     xlab = "Track Popularity", 
     col = "blue")

```
This now gives us a slightly right skewed distribution with a peak near the 50-60 range and a range of track_popularity now from 5-100. We will use this new filtered dataset for our analysis going forward. 

### Numerical Variables

Looking at the attributes in this dataset we have many to choose from. There are both numerical and categorical variables to consider. Features like tempo, daceability and duration are given as numbers, where as variables like genre, key and artist are categorical. Here is a list of some of the key variables in the datset and what they represent. 

```{r, echo=FALSE}
library(tibble)
library(knitr)

# Create the table using tibble
data_dictionary <- tibble(
  Attribute = c(
    "track_name", "track_artist", "track_popularity", "track_album_release_date", "playlist_name",
    "playlist_genre", "playlist_subgenre", "danceability", "energy", "key", "loudness", "mode",
    "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "tempo", "duration_ms"
  ),
  Description = c(
    "Song Name",
    "Song Artist",
    "Song Popularity (0-100) where higher is better",
    "Date when album released",
    "Name of playlist",
    "Playlist genre",
    "Playlist subgenre",
    "Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.",
    "Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.",
    "The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.",
    "The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.",
    "Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.",
    "Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audiobook, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music.",
    "A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.",
    "Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.",
    "Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.",
    "A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).",
    "The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.",
    "Duration of song in milliseconds"
  )
)

# Print the table using knitr::kable
kable(data_dictionary, caption = "Data Dictionary for Spotify Dataset")

```
While variables such as valence (how positive a song sounds) and danceability provide some unique and interesting characteristics. A similar study suggests that the numerical attributes most associated with popularity are loudness, acousticness and duration (Vitolo 2023), I made a coorelation chart with all numerical predictors to see if this is the case. 

```{r, echo=FALSE}

library(corrplot)
corr_data <- spotify_popularity %>%
  select(track_popularity, danceability, energy, loudness, valence, tempo, duration_ms, liveness, instrumentalness, tempo, speechiness, acousticness) %>%
  cor(use = "complete.obs")
corrplot(corr_data, method = "color")

```
In this graph we want to focus on the first row and first column which indicate our target variable, track_popularity. A darker blue shade indicated a stronger positive coorelation while a darker red share indicates a stronger negative one. There are not a ton of very dark squares in these two sections, indicating other variables that explain the variability of track_popularity, however we do see that danceability, loudness and valence have slight positive coorelations with popularity and  instrumentalness, energy, duration have slightly negative ones. Danceablity and valence also are fairly strongly coorelated with each other (indicating positive sounding songs are also more danceable) so we may have to consider this in our models down the road. 

We also see that acoustics is strongly negatively associated with two other variables. I decided to not include this attribute in the models in this report as it did not improve model performance much

### Categorical Variables

Categorical variables also can significantly contribute to track_popularty in this dataset. One of which I wanted to take a look at is genre. In the data, genre is classified as the variable playlist_genre, as these songs were pulled from playlists on spotify that were definied bu an overarching genre and subsequent sub-genres. There were 6 overarching genres; pop, edm, rock, latin, r&b and rap. Here is how their popularity is distributed in both a box and density plot

```{r}
ggplot(spotify_popularity, aes(x = playlist_genre, y = track_popularity, fill = playlist_genre)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Popularity Across Genres", x = "Genre", y = "Danceability")

ggplot(spotify_popularity, aes(x = track_popularity, fill = playlist_genre)) +
  geom_density(alpha = 0.6) +
  labs(title = "Popularity by Genre", x = "Popularity", y = "Density") +
  theme(legend.position = "bottom")
```

I find these charts, interesting because the box plot shows that latin and pop have the highest median popularity, but you can also see in the density chart that rock and rap have greater number of songs with higher popularities. In both charts, edm seems to be the overall least popular genre with some outliers with very high popularities. Here are the mean popularity score by genre as well 

```{r, echo=FALSE}
spotify_popularity %>%
  group_by(playlist_genre) %>%
  summarize(
    n = n(),
    avg_popularity = mean(track_popularity, na.rm = TRUE)
  ) %>%
  arrange(desc(avg_popularity))
```


Lastly, I was personally interested in how a song's key efects it's popularity. A key in music is kind of like the home base of a song. It indicated the main scale used for the majority of notes within a song's melody and chord structure. There is a lot of psychology behind musical key's I have always been interested in. For example, a casino generally tunes all of it's slot machines to a C major chord as it scientifically is the most please to the human ear. I was interested to know if this also played a role in music listening. Here are some graphic results. 

```{r}
key_mapping <- c("C", "C♯", "D", "D♯", "E", "F", "F♯", "G", "G♯", "A", "A♯", "B")
spotify_popularity$key_label <- key_mapping[spotify_popularity$key + 1]

key_counts <- table(spotify_popularity$key_label)

pie(key_counts, 
    main = "Proportion of Musical Keys", 
    col = rainbow(length(key_counts)))

avg_popularity_by_key <- spotify_popularity %>%
  group_by(key_label) %>%
  summarize(avg_popularity = mean(track_popularity, na.rm = TRUE))

ggplot(avg_popularity_by_key, aes(x = reorder(key_label, avg_popularity), y = avg_popularity, fill = key_label)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Average Popularity by Musical Key", x = "Key", y = "Average Popularity") +
  theme_minimal() +
  theme(legend.position = "none")
```
Interestingly, according to this data, the key of G# has the highest average popularity (although it represents a small proportion of the overall keys in the dataset). My prediction of C seems to be right in the middle with average popularity, but has a large poportion of the data. Lastly, it was interesting to see the key of C# being well represented in this dataset. From an instrumentalist perspective, this isn't a super popular key for songs to be in (that I have played), so i wonder if it is a good key for electronic music and computer generated backing trakcs for pop songs. 

If we run an anova test for key in relation to track_popularity we see that the p value is very small, signifying that different keys tend to have different popularitie averages. However it doesn't seem to represent a lot of thevariability in the data as the sum of squares for key (21,583) is very small compared to the residuals (11,987,776), indicating a minor effect on track_popularity as a whole.

```{r, echo=FALSE}

anova_result <- aov(track_popularity ~ as.factor(key), data = spotify_popularity)
summary(anova_result)
```
# Models 

## Linear Models

We are going to start the modeling process with the null model to determine the average popularity among all songs with no predictors. 

```{r, echo=FALSE}
null_model <- lm(track_popularity ~ 1, data = spotify_popularity)
summary(null_model)
```
This estimate of 48.69 gives us the mean value of track_popularity across all observations with the absence of predictors. This essentially is saying if we have a song added to our dataset that we know nothing about, we can predict it's popularity will be around 48.69. 

This null model provides the baseline RSE (20.52, and future models should aim to reduce this value.

Now we're going to run a simple linear model with our predictors most associated with track_popularity based on our corelation matrix. These are danceability, energy, valence, loudness, instrumentalness, and duration. 

```{r}
lm_model <- lm(track_popularity ~ danceability + energy + valence + loudness + instrumentalness + duration_ms, 
               data = spotify_popularity)

# Summary of the regression model
summary(lm_model)
```
As expected, our residual standard error decreased to 19.87 for this model, a decrease but not that drastic. We can also see that most of the predictors here are significant (minus danceability), however our R squared is very low at .06. This suggests that only about 6% of the variability in this dataset is represented by this model. 


The next model I added interaction terms. Energy:loudness and valence:energy, and instrumentalness:loudness. I also removed danceability from this due to it's low significance. 
```{r, echo=FALSE}
lm_model_interaction <- lm(track_popularity ~ 
                             energy + valence + loudness + instrumentalness + duration_ms +
                             energy:loudness + valence:energy + instrumentalness:loudness, 
                           data = spotify_popularity)

# View the summary of the updated model
summary(lm_model_interaction)

```
While all of these predictors are significant. Our RSE (19.79) and R squared didn't really improve enough to justify using this more complicated linear model. 



Next I wanted to add a categorical variable of playlist_genre and see if that has an effect on model performance. We are going to use the baseline simple linear model (no interaction terms) with playlist_genre now added as a factor. I also reincluded danceability which i will explain.  

```{r, echo=FALSE}
lm_model_genre <- lm(track_popularity ~ energy + valence + loudness + instrumentalness + duration_ms + danceability + factor(playlist_genre), 
                     data = spotify_popularity)

# View the summary of the model
summary(lm_model_genre)
```
We now see danceability as a significant predictor in this model and the R squared imporve to .08 (still very small). The RSE remains about the same. We also notice a massive negative coorelation with energy of -25.2, indicating that for every one unit increase in energy, we can expect around a 25 point deduction in popularity. 

We also notice how the genres interact with each other. In this model EDM is our reference genre. We know from the previous visualizations that this should be our least popular genre and this model supports that, with all coefficients being positive. We can now compare the Mean Square Error of the three models. 

However why is dancability now significant where it wasn't before and valence is not? The answer is becasue based on our coorelation matrix, danceability and valence have a positive coorelation, indicating that more positive sounding songs are also more danceable. When we added the genre variable, the significance of danceability improves  because playlist_genre helps explain variability that overlaps with danceability. We ca see this in a graph showing dancability accross genres. 

```{r, echo=FALSE}
ggplot(spotify_popularity, aes(x = danceability, fill = playlist_genre)) +
  geom_density(alpha = 0.6) +
  labs(title = "Danceability by Genre", x = "Popularity", y = "Density") +
  theme(legend.position = "bottom")
```
The "undancability" of rock and the high danceability of latin music contribute to that variable now being significant with the genre category added to the model. 

Next I compares the Mean Square Errrors of the thre elinear models. 

```{r, echo=FALSE}
# Calculate predictions for each model
original_predictions <- predict(lm_model, spotify_popularity)
interaction_predictions <- predict(lm_model_interaction, spotify_popularity)
genre_predictions <- predict(lm_model_genre, spotify_popularity)

# Calculate residuals for each model
original_residuals <- spotify_popularity$track_popularity - original_predictions
interaction_residuals <- spotify_popularity$track_popularity - interaction_predictions
genre_residuals <- spotify_popularity$track_popularity - genre_predictions

# Calculate MSE for each model
original_mse <- mean(original_residuals^2)
interaction_mse <- mean(interaction_residuals^2)
genre_mse <- mean(genre_residuals^2)

# Print the MSE values
cat("MSE for Original Model:", original_mse, "\n")
cat("MSE for Interaction Model:", interaction_mse, "\n")
cat("MSE for Model with Playlist Genre:", genre_mse, "\n")
```

Although these MSE's are all fairly large, we can see the one with the playlist genre's is a fair amount lower, showing it is the best option of the three. 

### Poisson Model 

When checking the mean and variance of our target variable track_popularity. We can see they are not close at all. Because of this and since track_popularity is a discrete variable and not a count. I decided a poisson regression would not be appropriate for this data. 

```{r, echo=FALSE}
mean_popularity <- mean(spotify_popularity$track_popularity)
variance_popularity <- var(spotify_popularity$track_popularity)

# Print the results
cat("Mean of Track Popularity:", mean_popularity, "\n")
cat("Variance of Track Popularity:", variance_popularity, "\n")
```
### Logistic Regression 

I did runa logistic regression model that I included in the appendix. I used a binary variable based on a threshold of track_popularity being above a score of 60. I did not include this model in the main report as it did not perorm as well as other models. However some key takeaways are:

1. Tracks with high danceability and loudness are more likely to be popular, emphasizing that engaging, upbeat songs resonate better with listeners.

2. Higher instrumentalness and energy negatively impact popularity. This may indicate that excessively energetic or instrumental tracks appeal less to mainstream audiences.

3. Rock has the highest odds ratio, followed by Pop and Latin, indicating that these genres are much more likely to have tracks above the 60-popularity threshold compared to EDM.

4. Tracks with higher danceability are ~2.39 times more likely to achieve high popularity. This suggests that engaging, dance-friendly tracks resonate well with Spotify audiences.

5. Instrumentalness also has a strong negative effect, reducing the odds of popularity by ~82% for every 1-unit increase.



### Mixed Effects Model

For the mixed effects model, I wanted to take a look at track_artist, which is what I believe is the real driving force behind the variability of track_popularity. The first thing I did was check how much variability this one variable actually accounts for. 

```{r, echo=FALSE}

spotify_popularity <- spotify_popularity %>%
  mutate(across(c(energy, valence, loudness, instrumentalness, duration_ms, danceability), scale))
# Calculate the overall variance in track_popularity
total_variance <- var(spotify_popularity$track_popularity)

# Calculate the mean popularity for each artist
artist_means <- aggregate(track_popularity ~ track_artist, data = spotify_popularity, FUN = mean)

# Calculate variance between artists
between_variance <- var(artist_means$track_popularity)

# Calculate variance within artists
within_variance <- total_variance - between_variance

# Proportion of variance explained by artist
proportion_between <- between_variance / total_variance
proportion_within <- within_variance / total_variance

# Print results
cat("Total Variance:", total_variance, "\n")
cat("Between-Artist Variance:", between_variance, "\n")
cat("Within-Artist Variance:", within_variance, "\n")
cat("Proportion of Variance Explained by Artist (Between):", proportion_between, "\n")

```
62.2%! That is a lot of variability attributed to one variable. So next I ran a model with partial pooling, keeping track_artist as a random effect variable. 

```{r, include=FALSE}
library(lme4)

# Fit a mixed-effects model
mixed_model <- lmer(track_popularity ~ energy + valence + loudness + instrumentalness + duration_ms + danceability + factor(playlist_genre) + 
                      (1 | track_artist), 
                    data = spotify_popularity)

# Summary of the model
summary(mixed_model)

```
I didn't include all the model output (included in apendix) but here is the model i ran: 

mixed_model <- lmer(track_popularity ~ energy + valence + loudness + instrumentalness + duration_ms + danceability + factor(playlist_genre) + (1 | track_artist)

This treats track_artist as a random effects variable, creating a multilevel model as each indivdual track is nested within a particular artist. 

And here are the resulting AIC and BIC comparisons for the three models. The original linear model, the linear model with genre as a categorial variable and the mixed effects model. 
                  
```{r}
AIC(lm_model, lm_model_genre, mixed_model)
BIC(lm_model, lm_model_genre, mixed_model)
```
We see that the AIC and BIC is the lowest for the mixed model we ran. Other results from the mixed model is that the Track Artist Variance is 119.2 with a standard deviation of 10.92, This indicates that artist-level differences have a meaningful impact on popularity.

I ran multiple other multilevel models including adding interaction terms, changing the main level to genre, and playing around with random effects. However none of the models really lowered the AIC enough to be worth the extra complexity. 

# Results

This project aimed to uncover the relationship between Spotify track attributes and their popularity, focusing on both audio features and categorical variables such as genre and artist information. Below are the major findings from the analysis:

1. Track Popularity Distribution

The initial exploration revealed a large spike in tracks with a popularity score of 0-5, attributed to certain artists having disproportionately low engagement. By filtering out tracks with a popularity score below 5, a more meaningful dataset was created, resulting in a slightly right-skewed distribution of popularity scores ranging from 5 to 100.

2. Correlation Analysis

A correlation heatmap identified several audio attributes with slight correlations to track popularity:
Positive correlations: Loudness, valence, danceability.
Negative correlations: Energy, instrumentalness, and duration.
These correlations suggest that upbeat, positive, and danceable tracks tend to perform better, while longer, more instrumental, or overly energetic tracks are less popular.

3. Genre-Level Analysis

Genre significantly influenced track popularity, as evidenced by the addition of playlist_genre in the models:
Latin and Pop had the highest average popularity scores, while EDM had the lowest.

4. Key and Musical Preferences

Analyzing musical keys revealed that certain keys (e.g., G♯) had higher average popularity, though these results might be influenced by smaller sample sizes for some keys. An ANOVA test confirmed that keys can influence popularity, but the effect size was relatively small compared to residual variability.

5. Linear Models

Several linear models were tested:
- The baseline Null model with no predictors had a mean popularity estimate of 48.69 and a residual standard error (RSE) of 20.52.
- Adding predictors like loudness, valence, energy, instrumentalness, and duration improved the RSE to 19.87, but the model explained only ~6% of the variance (R² = 0.063).
- Adding interaction terms (e.g., energy:loudness) provided minor improvements (RSE = 19.79, R² = 0.07).
- Including playlist_genre significantly improved the model, with the lowest MSE (385.8) among all linear models tested.

6. Mixed-Effects Model

Treating track_artist as a random effect in a mixed-effects model significantly improved performance:
- The mixed-effects model had the lowest AIC (244,911) and BIC (245,027), outperforming all linear models.
- Track artist accounted for 62.3% of the total variance in track popularity, highlighting its importance.
Fixed effects in the mixed model showed:
- Strong negative effects for energy (-2.83) and instrumentalness (-1.00).
- Positive effects for loudness (2.42) and danceability (0.59).
- Genre-level differences were pronounced, with genres like rock and pop significantly outperforming EDM.

# Discussion and Validation 

### Key Insights

Artist Effect on Popularity:

The mixed-effects model demonstrated that track_artist accounts for over 60% of the variability in track popularity. This suggests that artist-level factors (e.g., fan base size, marketing reach, or brand recognition) play a dominant role in determining popularity, potentially overshadowing track-level attributes like loudness or valence.

Genre as a Significant Predictor:

While playlist_genre improved model performance, the mixed model indicated that genre alone does not explain much variance when compared to artist-level effects. However, rock and pop tracks consistently outperformed EDM, aligning with general trends in music consumption.

Impact of Track-Level Features Validation:

The Vitolo Thesis indicated that loudness is the most important factor in determining track popularity and my study also confirmed this. Loudness, danceability, and valence positively influenced popularity, supporting the idea that energetic and positive-sounding tracks resonate better with audiences. However, these effects were relatively small, highlighting the complexity of predicting track success. The thesis also states that duration has a strong negative effect on popularity, wwhich is somehat supported by my findings. Duration_ms has a significant but relatively modest effect on track popularity compared to other predictors. Its impact is consistent across models, but variables like energy, loudness, and playlist_genre contribute more substantially to explaining the variability in track popularity. This suggests that while duration matters, it is not a primary driver of popularity and is more context-dependent. However there is probably a baseline threshold song length for when this starts to go down that I did not explore 

In the paper "What makes a Song Trend" the authors also verify lively, upbeat songs as being the most popular, stating "The most popular songs tend to be the more exciting, radio friendly songs...These songs follow a formulaic, pop-friendly sound, with a danceable music structure that tends to put the audience in a good mood." This paper also states the uncertainty of these variables through cluster analysis as well, stating that the musical artist of each song plays an important aspect, similar to what i discovered here as well. 




### Limitations and Future Steps
This study provided some insights into the factors influencing Spotify track popularity. However, there are notable limitations that suggest areas for improvement and future research directions. First, the dataset was filtered to exclude tracks with popularity scores below 5, which introduced potential bias. This filtering may have excluded niche or experimental tracks that, while less popular, could still hold significant cultural or artistic value. Additionally, the classification of genres was relatively broad (e.g., "Pop" or "Rock"), which might oversimplify the diversity within these categories. Nuances such as subgenres or cultural contexts were not captured, potentially obscuring finer details in genre-based popularity trends. Lastly, this analysis did not incorporate temporal data, such as release dates or playlist additions, which could reveal how track popularity evolves over time.

Future research and improvements to determine which track components really do affect popularity would be to maybe look at a datset containing all one artist. That way we wuould be able to compare their individual songs against each other rather than use a random sample taken from many different artists. To get really into the weeds, we could also integrate demographic or geographic data, as it could offer audience-specific insights, shedding light on how preferences vary across listener groups and regions. These future directions, combined with the findings of this study, could provide a more comprehensive and nuanced understanding of what drives Spotify track popularity.





