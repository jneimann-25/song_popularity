---
title: "Final Report"
author: "Jonathan Neimann"
date: "2024-12-08"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
spotify30k = read.csv("spotify_songs.csv")
spotify30k <- spotify30k[grepl("[a-zA-Z]", spotify30k$track_artist), ]
```

# Abstract

This study explores the relationship between various song attributes and their popularity on Spotify, leveraging a dataset of nearly 30,000 songs obtained from the Spotify API. Spotify calculates popularity using an algorithm primarily based on the total number of plays a track has had, the recency of those plays and is scaled form 0-100. The analysis focuses on understanding how specific audio features and contextual metadata—such as genre, acousticness, danceability, valence, duration, key, and mode—correlate with this track popularity. Through a combination of descriptive and inferential statistical methods, alongside data visualizations, key patterns in the data are highlighted. Predictive modeling techniques are employed to attempt to identify the most influential factors driving popularity, hopefully offering insights for artists, producers, and marketers aiming to enhance the appeal of their tracks in the competitive music streaming landscape.

# Introduction

The rapid evolution of music streaming platforms has revolutionized the way audiences consume music, with Spotify emerging as the leading player in this space. Spotify provides not only an extensive catalog of songs but also rich metadata and audio analysis for each track, offering a unique opportunity to study the factors that drive a song's popularity. Among these is track popularity, an algorithmically calculated metric primarily influenced by the total number of plays a track has received and the recency of those plays. This metric is measured on a 0-100 scale and provides valuable insights into user preferences and the dynamics of modern music consumption.

This project comes from a place of personal interest, inspired by my academic background and passion for music. Having completed an undergraduate degree in music, I have long been fascinated by the interplay between musical composition and audience reception. My love for music and curiosity about how modern algorithms shape music discovery motivated me to undertake this project. The connection between audio attributes and commercial success represents a compelling intersection of art and data science, which I sought to explore through this work.

Using the "30000 Spotify Songs" dataset from Kaggle, which includes nearly 30,000 tracks, this research focuses on understanding the relationship between key audio attributes and contextual factors that affect a track's popularity on Spotify. Attributes such as acousticness, danceability, valence, duration, key, and mode—derived from Spotify's audio analysis—describe intrinsic musical qualities. These features, combined with metadata such as genre provide a comprehensive framework to analyze patterns in popular music.

Despite the rich dataset, challenges emerged during the analysis, particularly with incomplete or non-standardized metadata. The track_artist field, in particular, made it difficult to fully interpret the popularity metric. Addressing this issue required key emphasis on this variable.

This research employs descriptive analytics, data visualization, and predictive modeling to identify trends and influential factors. The findings aim to shed light on how various song attributes offer insights for artists, producers, and marketers in crafting music that resonates with audiences. By exploring the interplay of musical characteristics and popularity, this project combines statistics and my passion for music to contribute to a deeper understanding of what makes a song successful in the competitive streaming landscape.

# Method

## Visualizations

The first step of this process was to analyze the track_popularity metric from the dataset using various graphs to visualize the data and what we are dealing with. There were many different graphs I explored starting with the most basic of just graphing the density of the target variable. 

```{r, echo=FALSE}
#popularity distribution
hist(spotify30k$track_popularity, 
     main = "Distribution of Track Popularity", 
     xlab = "Track Popularity", 
     col = "blue")
```

We can see right away that there is a significant spike at the very lower ends of popularity and then a slightly left skewed distribution after that. I conducted some tests to determine the main driving force of this spike was track_artist and that within this sample of songs, some artists just did not have the same pull power of other artists in the dataset. Because of this I decided to eliminate all observations that had a track_populartity of below 5. Although this is eliminating some data (around 4000 observations) and created bias, I felt it was necessary to perform proper analysis as it reduces noise significantly and focuses on  on tracks with some level of audience engagement.

Here is the resulting distribution for this dataset. 

```{r, echo=FALSE}
# Create a new dataframe where track_popularity is 5 or higher
spotify_popularity <- spotify30k[spotify30k$track_popularity >= 5, ]

hist(spotify_popularity$track_popularity, 
     main = "Distribution of Track Popularity", 
     xlab = "Track Popularity", 
     col = "blue")

```
This now gives us a slightly right skewed distribution with a peak near the 50-60 range and a range of track_popularity now from 5-100. We will use this new filtered dataset for our analysis going forward. 

### Numerical Variables

Looking at the attributes in this dataset we have many to choose from. There are both numerical and categorical variables to consider. Features like tempo, daceability and duration are given as numbers, where as variables like genre, key and artist are categorical. Here is a list of some of the key variables in the datset and what they represent. 

```{r, echo=FALSE}
# Load the knitr package
library(knitr)

# Create a data frame for the data dictionary
data_dictionary <- data.frame(
  Variable = c(
    "track_name", "track_artist", "track_popularity", "track_album_release_date", "playlist_name",
    "playlist_genre", "playlist_subgenre", "danceability", "energy", "key", "loudness", "mode",
    "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "tempo", "duration_ms"
  ),
  Description = c(
    "Song Name",
    "Song Artist",
    "Song Popularity (0-100) where higher is better",
    "Date when album released",
    "Name of playlist",
    "Playlist genre",
    "Playlist subgenre",
    "Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.",
    "Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.",
    "The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.",
    "The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.",
    "Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.",
    "Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audiobook, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.",
    "A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.",
    "Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.",
    "Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.",
    "A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).",
    "The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.",
    "Duration of song in milliseconds"
  )
)

# Print the table using knitr
print(data_dictionary)
```
While variables such as valence (how positive a song sounds) and danceability provide some unique and interesting characteristics. A similar study suggests that the numerical attributes most associated with popularity are loudness, acousticness and duration (Vitolo 2023), I made a coorelation chart with all numerical predictors to see if this is the case. 

```{r, echo=FALSE}

library(corrplot)
corr_data <- spotify_popularity %>%
  select(track_popularity, danceability, energy, loudness, valence, tempo, duration_ms, liveness, instrumentalness, tempo, speechiness) %>%
  cor(use = "complete.obs")
corrplot(corr_data, method = "color")

```
In this graph we want to focus on the first row and first column which indicate our target variable, track_popularity. A darker blue shade indicated a stronger positive coorelation while a darker red share indicates a stronger negative one. There are not a ton of very dark squares in these two sections, indicating other variables that explain the variability of track_popularity, however we do see that danceability, loudness and valence have slight positive coorelations with popularity and  instrumentalness, energy, duration have slightly negative ones. Danceablity and valence also are fairly strongly coorelated with each other (indicating positive sounding songs are also more danceable) so we may have to consider this in our models down the road. 

### Categorical Variables

Categorical variables also can significantly contribute to track_popularty in this dataset. One of which I wanted to take a look at is genre. In the data, genre is classified as the variable playlist_genre, as these songs were pulled from playlists on spotify that were definied bu an overarching genre and subsequent sub-genres. There were 6 overarching genres; pop, edm, rock, latin, r&b and rap. Here is how their popularity is distributed in both a box and density plot

```{r}
ggplot(spotify_popularity, aes(x = playlist_genre, y = track_popularity, fill = playlist_genre)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Danceability Across Genres", x = "Genre", y = "Danceability")

ggplot(spotify_popularity, aes(x = track_popularity, fill = playlist_genre)) +
  geom_density(alpha = 0.6) +
  labs(title = "Popularity by Genre", x = "Popularity", y = "Density") +
  theme(legend.position = "bottom")
```

I find these charts, interesting because the box plot shows that latin and pop have the highest median popularity, but you can also see in the density chart that rock and rap have greater number of songs with higher popularities. In both charts, edm seems to be the overall least popular genre with some outliers with very high popularities. Here are the mean popularity score by genre as well 

```{r, echo=FALSE}
spotify_popularity %>%
  group_by(playlist_genre) %>%
  summarize(
    n = n(),
    avg_popularity = mean(track_popularity, na.rm = TRUE)
  ) %>%
  arrange(desc(avg_popularity))
```


Lastly, I was personally interested in how a song's key efects it's popularity. A key in music is kind of like the home base of a song. It indicated the main scale used for the majority of notes within a song's melody and chord structure. There is a lot of psychology behind musical key's I have always been interested in. For example, a casino generally tunes all of it's slot machines to a C major chord as it scientifically is the most please to the human ear. I was interested to know if this also played a role in music listening. Here are some graphic results. 

```{r}
key_mapping <- c("C", "C♯", "D", "D♯", "E", "F", "F♯", "G", "G♯", "A", "A♯", "B")
spotify_popularity$key_label <- key_mapping[spotify_popularity$key + 1]

key_counts <- table(spotify_popularity$key_label)

pie(key_counts, 
    main = "Proportion of Musical Keys", 
    col = rainbow(length(key_counts)))

avg_popularity_by_key <- spotify_popularity %>%
  group_by(key_label) %>%
  summarize(avg_popularity = mean(track_popularity, na.rm = TRUE))

ggplot(avg_popularity_by_key, aes(x = reorder(key_label, avg_popularity), y = avg_popularity, fill = key_label)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Average Popularity by Musical Key", x = "Key", y = "Average Popularity") +
  theme_minimal() +
  theme(legend.position = "none")
```
Interestingly, according to this data, the key of G# has the highest average popularity (although it represents a small proportion of the overall keys in the dataset). My prediction of C seems to be right in the middle with average popularity, but has a large poportion of the data. Lastly, it was interesting to see the key of C# being well represented in this dataset. From an instrumentalist perspective, this isn't a super popular key for songs to be in (that I have played), so i wonder if it is a good key for electronic music and computer generated backing trakcs for pop songs. 

If we run an anova test for key in relation to track_popularity we see that the p value is very small, signifying that different keys tend to have different popularitie averages. However it doesn't seem to represent a lot of thevariability in the data as the sum of squares for key (21,583) is very small compared to the residuals (11,987,776), indicating a minor effect on track_popularity as a whole.

```{r, echo=FALSE}

anova_result <- aov(track_popularity ~ as.factor(key), data = spotify_popularity)
summary(anova_result)
```
## Models 

# Linear Models

We are going to start the modeling process with the null model to determine the average popularity among all songs with no predictors. 

```{r, echo=FALSE}
null_model <- lm(track_popularity ~ 1, data = spotify_popularity)
summary(null_model)
```
This estimate of 48.69 gives us the mean value of track_popularity across all observations with the absence of predictors. This essentially is saying if we have a song added to our dataset that we know nothing about, we can predict it's popularity will be around 48.69. 

This null model provides the baseline RSE (20.52, and future models should aim to reduce this value.

Now we're going to run a simple linear model with our predictors most associated with track_popularity based on our corelation matrix. These are danceability, energy, valence, loudness, instrumentalness, and duration. 

```{r}
lm_model <- lm(track_popularity ~ danceability + energy + valence + loudness + instrumentalness + duration_ms, 
               data = spotify_popularity)

# Summary of the regression model
summary(lm_model)
```
As expected, our residual standard error decreased to 19.87 for this model, a decrease but not that drastic. We can also see that most of the predictors here are significant (minus danceability), however our R squared is very low at .06. This suggests that only about 6% of the variability in this dataset is represented by this model. 

we can also check for multicollinearity with these predictors by running a VIF test. 

```{r, echo=FALSE}
library(car)
vif(lm_model)
```
We can see from these results that none of the predictors are coorelated much with each other (which is good). However I am still going to remove danceability from the next model due to it's low significance. 

The next model will add some interaction terms. Energy:loudness and valence:energy, and instrumentalness:loudness
```{r, echo=FALSE}
lm_model_interaction <- lm(track_popularity ~ 
                             energy + valence + loudness + instrumentalness + duration_ms +
                             energy:loudness + valence:energy + instrumentalness:loudness, 
                           data = spotify_popularity)

# View the summary of the updated model
summary(lm_model_interaction)

```
While all of these predictors are significant. Our RSE (19.79) and R squared didn't really improve enough to justify using this more complicated linear model. 



No we are going to add the categorical variable of playlist_genre and see if that has an effect on model performance. We are going to use the baseline simple linear model (no interaction terms) with playlist_genre now added as a factor 

```{r, echo=FALSE}
lm_model_genre <- lm(track_popularity ~ energy + valence + loudness + instrumentalness + duration_ms + danceability + factor(playlist_genre), 
                     data = spotify_popularity)

# View the summary of the model
summary(lm_model_genre)
```
We now see danceability as a significant predictor in this model and the R squared imporve to .08 (still very small). The RSE remains about the same. We also notice a massive negative coorelation with energy of -25.2, indicating that for every one unit increase in energy, we can expect around a 25 point deduction in popularity. 

We also notice how the genres interact with each other. In this model EDM is our reference genre. We know from the previous visualizations that this should be our least popular genre and this model supports that, with all coefficients being positive. We can now compare the Mean Square Error of the three models. 

```{r, echo=FALSE}
# Calculate predictions for each model
original_predictions <- predict(lm_model, spotify_popularity)
interaction_predictions <- predict(lm_model_interaction, spotify_popularity)
genre_predictions <- predict(lm_model_genre, spotify_popularity)

# Calculate residuals for each model
original_residuals <- spotify_popularity$track_popularity - original_predictions
interaction_residuals <- spotify_popularity$track_popularity - interaction_predictions
genre_residuals <- spotify_popularity$track_popularity - genre_predictions

# Calculate MSE for each model
original_mse <- mean(original_residuals^2)
interaction_mse <- mean(interaction_residuals^2)
genre_mse <- mean(genre_residuals^2)

# Print the MSE values
cat("MSE for Original Model:", original_mse, "\n")
cat("MSE for Interaction Model:", interaction_mse, "\n")
cat("MSE for Model with Playlist Genre:", genre_mse, "\n")
```

Although these MSE's are all fairly large, we can see the one with the playlist genre's is a fair amount lower, showing it is the best option of the three. 

### Poisson Model 

When checking the mean and variance of our target variable track_popularity. We can see they are not close at all. Because of this and since track_popularity is a discrete variable and not a count. I decided a poisson regression would not be appropriate for this data. 

```{r, echo=FALSE}
mean_popularity <- mean(spotify_popularity$track_popularity)
variance_popularity <- var(spotify_popularity$track_popularity)

# Print the results
cat("Mean of Track Popularity:", mean_popularity, "\n")
cat("Variance of Track Popularity:", variance_popularity, "\n")
```

### Mixed Effects Model

Now we get to track_artist, what I believe is the real driving force behind the variability of track_popularity. The first thing i want to do is check how much variability this one variable actually acounts for. 

```{r, echo=FALSE}

spotify_popularity <- spotify_popularity %>%
  mutate(across(c(energy, valence, loudness, instrumentalness, duration_ms, danceability), scale))
# Calculate the overall variance in track_popularity
total_variance <- var(spotify_popularity$track_popularity)

# Calculate the mean popularity for each artist
artist_means <- aggregate(track_popularity ~ track_artist, data = spotify_popularity, FUN = mean)

# Calculate variance between artists
between_variance <- var(artist_means$track_popularity)

# Calculate variance within artists
within_variance <- total_variance - between_variance

# Proportion of variance explained by artist
proportion_between <- between_variance / total_variance
proportion_within <- within_variance / total_variance

# Print results
cat("Total Variance:", total_variance, "\n")
cat("Between-Artist Variance:", between_variance, "\n")
cat("Within-Artist Variance:", within_variance, "\n")
cat("Proportion of Variance Explained by Artist (Between):", proportion_between, "\n")

```
62.2%! That is a lot of variability attributed to one variable. So nect i want to run the model with partial pooling, keeping track_artist as a random effect variable. 

```{r, include=FALSE}
library(lme4)

# Fit a mixed-effects model
mixed_model <- lmer(track_popularity ~ energy + valence + loudness + instrumentalness + duration_ms + danceability + factor(playlist_genre) + 
                      (1 | track_artist), 
                    data = spotify_popularity)

# Summary of the model
summary(mixed_model)

```
I didn't include all the model output but here is the model i ran: 

mixed_model <- lmer(track_popularity ~ energy + valence + loudness + instrumentalness + duration_ms + danceability + factor(playlist_genre) + (1 | track_artist)

This treats track_artist as a random effects variable, creating a multilevel model as each indivdual track is nested within a particular artist. 

And here are the resulting AIC and BIC comparisons. 
                  
```{r}
AIC(lm_model, lm_model_genre, mixed_model)
BIC(lm_model, lm_model_genre, mixed_model)
```
We see that the AIC and BIC is the lowest for the mixed model we ran. Other results from the mixed model is that the Track Artist Variance is 119.2 with a standard deviation of 10.92, This indicates that artist-level differences have a meaningful impact on popularity.

I ran multiple other multilevel models including adding interaction terms, changing the main level to genre, and playing around with random effects. However none of the models really lowered the AIC enough to be worth the extra complexity. 

# Results
This project aimed to uncover the relationship between Spotify track attributes and their popularity, focusing on both audio features and metadata, such as genre and artist information. Below are the major findings from the analysis:

1. Track Popularity Distribution
The initial exploration revealed a large spike in tracks with a popularity score of 0-5, attributed to certain artists having disproportionately low engagement. By filtering out tracks with a popularity score below 5, a more meaningful dataset was created, resulting in a slightly right-skewed distribution of popularity scores ranging from 5 to 100.

2. Correlation Analysis
A correlation heatmap identified several audio attributes with slight correlations to track popularity:
Positive correlations: Loudness, valence, danceability.
Negative correlations: Energy, instrumentalness, and duration.
These correlations suggest that upbeat, positive, and danceable tracks tend to perform better, while longer, more instrumental, or overly energetic tracks are less popular.

3. Genre-Level Analysis
Genre significantly influenced track popularity, as evidenced by the addition of playlist_genre in the models:
Latin and Pop had the highest average popularity scores, while EDM had the lowest.
The mixed-effects model confirmed that playlist_genre is a key predictor, with rock, pop, and rap genres showing higher coefficients compared to EDM (the reference genre).

4. Key and Musical Preferences
Analyzing musical keys revealed that certain keys (e.g., G♯) had higher average popularity, though these results might be influenced by smaller sample sizes for some keys. An ANOVA test confirmed that keys significantly influence popularity, but the effect size was relatively small compared to residual variability.

5. Linear Models
Several linear models were tested:
The baseline model with no predictors had a mean popularity estimate of 48.69 and a residual standard error (RSE) of 20.52.
Adding predictors like loudness, valence, energy, instrumentalness, and duration improved the RSE to 19.87, but the model explained only ~6% of the variance (R² = 0.063).
Adding interaction terms (e.g., energy:loudness) provided minor improvements (RSE = 19.79, R² = 0.07).
Including playlist_genre significantly improved the model, with the lowest MSE (385.8) among all linear models tested.

6. Mixed-Effects Model
Treating track_artist as a random effect in a mixed-effects model significantly improved performance:
AIC/BIC Comparison: The mixed-effects model had the lowest AIC (244,911) and BIC (245,027), outperforming all linear models.
Variance Analysis: Track artist accounted for 62.3% of the total variance in track popularity, highlighting its importance.
Fixed effects in the mixed model showed:
Strong negative effects for energy (-2.83) and instrumentalness (-1.00).
Positive effects for loudness (2.42) and danceability (0.59).
Genre-level differences were pronounced, with genres like rock and pop significantly outperforming EDM.

# Discussion

### Key Insights

Artist Effect on Popularity:

The mixed-effects model demonstrated that track_artist accounts for over 60% of the variability in track popularity. This suggests that artist-level factors (e.g., fan base size, marketing reach, or brand recognition) play a dominant role in determining popularity, potentially overshadowing track-level attributes like loudness or valence.

Genre as a Significant Predictor:

While playlist_genre improved model performance, the mixed model indicated that genre alone does not explain much variance when compared to artist-level effects. However, rock and pop tracks consistently outperformed EDM, aligning with general trends in music consumption.

Impact of Track-Level Features:

Loudness, danceability, and valence positively influenced popularity, supporting the idea that energetic and positive-sounding tracks resonate better with audiences. However, these effects were relatively small, highlighting the complexity of predicting track success.

Musical Key:

Despite some keys showing higher average popularity, key alone was not a strong predictor. This aligns with the idea that modern audiences might not consciously prefer certain musical keys over others in the streaming era.

Limitations
Dataset Bias: Filtering out tracks with popularity <5 introduced bias, potentially excluding niche or experimental tracks that still have value.
Simplistic Genre Classification: Broad genres (e.g., "Pop") might oversimplify the diversity within each category, missing nuances like subgenre or cultural context.
Lack of Temporal Data: The analysis did not account for the temporal dynamics of popularity (e.g., how a song's popularity evolves over time).
Future Directions
Time-Series Analysis:
Incorporate temporal data (e.g., release date, playlist additions) to explore how track popularity changes over time and identify trends.
More Granular Genre Analysis:
Investigate subgenres to better understand the nuanced relationship between genre and popularity.
Artist-Level Predictors:
Explore additional artist-level predictors, such as follower count or album success, to enhance the mixed-effects model.
Audience-Specific Insights:
Use demographic or geographic data (if available) to investigate how preferences differ across listener groups.
By combining these directions with the insights gained from this study, future research could provide a more comprehensive understanding of what drives Spotify track popularity. Let me know if you'd like to refine or add to these sections!





